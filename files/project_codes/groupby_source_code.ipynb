{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\a_kok\\\\Desktop\\\\Dersler\\\\IE 582\\\\Project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/Project Data/train.csv')\n",
    "test = pd.read_csv('D:/Project Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.copy()\n",
    "df_test = test.copy()\n",
    "df.drop_duplicates(inplace=True) # Train set has a lot of duplicates. Since timestamp with split seconds precision can't\n",
    "# be same for different users and different actions, we drop all the duplicates.df = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>contentid</th>\n",
       "      <th>user_action</th>\n",
       "      <th>sellingprice</th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>businessunit</th>\n",
       "      <th>product_gender</th>\n",
       "      <th>category_id</th>\n",
       "      <th>Level1_Category_Id</th>\n",
       "      <th>Level1_Category_Name</th>\n",
       "      <th>Level2_Category_Id</th>\n",
       "      <th>Level2_Category_Name</th>\n",
       "      <th>Level3_Category_Id</th>\n",
       "      <th>Level3_Category_Name</th>\n",
       "      <th>gender</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-02T22:26:14.023Z</td>\n",
       "      <td>39918893.0</td>\n",
       "      <td>favorite</td>\n",
       "      <td>3099.0</td>\n",
       "      <td>PerfectCare 600 EW6F449ST A+++ 9 KG 1400 Devir...</td>\n",
       "      <td>8511.0</td>\n",
       "      <td>Electrolux</td>\n",
       "      <td>Beyaz Eşya</td>\n",
       "      <td>Unisex</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>Elektronik</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>Beyaz Eşya</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>Çamaşır Makinesi</td>\n",
       "      <td>F</td>\n",
       "      <td>425</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-12-08T23:15:04.603Z</td>\n",
       "      <td>3558544.0</td>\n",
       "      <td>favorite</td>\n",
       "      <td>3079.0</td>\n",
       "      <td>WW90J5475FW A+++ 1400 Devir 9 kg Çamaşır Makinesi</td>\n",
       "      <td>3228.0</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>Beyaz Eşya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>Elektronik</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>Beyaz Eşya</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>Çamaşır Makinesi</td>\n",
       "      <td>F</td>\n",
       "      <td>425</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-12-05T16:19:01.157Z</td>\n",
       "      <td>31292729.0</td>\n",
       "      <td>favorite</td>\n",
       "      <td>3999.0</td>\n",
       "      <td>KM 9711 A++ 9 kg Çamaşır Kurutma Makinesi</td>\n",
       "      <td>10989.0</td>\n",
       "      <td>Vestel</td>\n",
       "      <td>Beyaz Eşya</td>\n",
       "      <td>Unisex</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>Elektronik</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>Beyaz Eşya</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>Kurutma Makinesi</td>\n",
       "      <td>F</td>\n",
       "      <td>425</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-05T16:28:00Z</td>\n",
       "      <td>6363103.0</td>\n",
       "      <td>visit</td>\n",
       "      <td>2544.0</td>\n",
       "      <td>CMI 9710 A+++ 1000 Devir 9 kg Çamaşır Makinesi</td>\n",
       "      <td>10989.0</td>\n",
       "      <td>Vestel</td>\n",
       "      <td>Beyaz Eşya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>Elektronik</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>Beyaz Eşya</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>Çamaşır Makinesi</td>\n",
       "      <td>F</td>\n",
       "      <td>425</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-12-02T22:26:59Z</td>\n",
       "      <td>39918893.0</td>\n",
       "      <td>visit</td>\n",
       "      <td>3099.0</td>\n",
       "      <td>PerfectCare 600 EW6F449ST A+++ 9 KG 1400 Devir...</td>\n",
       "      <td>8511.0</td>\n",
       "      <td>Electrolux</td>\n",
       "      <td>Beyaz Eşya</td>\n",
       "      <td>Unisex</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>Elektronik</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>Beyaz Eşya</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>Çamaşır Makinesi</td>\n",
       "      <td>F</td>\n",
       "      <td>425</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time_stamp   contentid user_action  sellingprice  \\\n",
       "0  2020-12-02T22:26:14.023Z  39918893.0    favorite        3099.0   \n",
       "1  2020-12-08T23:15:04.603Z   3558544.0    favorite        3079.0   \n",
       "2  2020-12-05T16:19:01.157Z  31292729.0    favorite        3999.0   \n",
       "3      2020-12-05T16:28:00Z   6363103.0       visit        2544.0   \n",
       "4      2020-12-02T22:26:59Z  39918893.0       visit        3099.0   \n",
       "\n",
       "                                        product_name  brand_id  brand_name  \\\n",
       "0  PerfectCare 600 EW6F449ST A+++ 9 KG 1400 Devir...    8511.0  Electrolux   \n",
       "1  WW90J5475FW A+++ 1400 Devir 9 kg Çamaşır Makinesi    3228.0     Samsung   \n",
       "2          KM 9711 A++ 9 kg Çamaşır Kurutma Makinesi   10989.0      Vestel   \n",
       "3     CMI 9710 A+++ 1000 Devir 9 kg Çamaşır Makinesi   10989.0      Vestel   \n",
       "4  PerfectCare 600 EW6F449ST A+++ 9 KG 1400 Devir...    8511.0  Electrolux   \n",
       "\n",
       "  businessunit product_gender  category_id  Level1_Category_Id  \\\n",
       "0   Beyaz Eşya         Unisex       1272.0              1071.0   \n",
       "1   Beyaz Eşya            NaN       1272.0              1071.0   \n",
       "2   Beyaz Eşya         Unisex       1276.0              1071.0   \n",
       "3   Beyaz Eşya            NaN       1272.0              1071.0   \n",
       "4   Beyaz Eşya         Unisex       1272.0              1071.0   \n",
       "\n",
       "  Level1_Category_Name  Level2_Category_Id Level2_Category_Name  \\\n",
       "0           Elektronik              1212.0           Beyaz Eşya   \n",
       "1           Elektronik              1212.0           Beyaz Eşya   \n",
       "2           Elektronik              1212.0           Beyaz Eşya   \n",
       "3           Elektronik              1212.0           Beyaz Eşya   \n",
       "4           Elektronik              1212.0           Beyaz Eşya   \n",
       "\n",
       "   Level3_Category_Id Level3_Category_Name gender  unique_id   type  \n",
       "0              1272.0     Çamaşır Makinesi      F        425  train  \n",
       "1              1272.0     Çamaşır Makinesi      F        425  train  \n",
       "2              1276.0     Kurutma Makinesi      F        425  train  \n",
       "3              1272.0     Çamaşır Makinesi      F        425  train  \n",
       "4              1272.0     Çamaşır Makinesi      F        425  train  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_stamp                   0\n",
       "contentid                    2\n",
       "user_action                  0\n",
       "sellingprice             32013\n",
       "product_name              2184\n",
       "brand_id                  2184\n",
       "brand_name                2184\n",
       "businessunit              2184\n",
       "product_gender          234595\n",
       "category_id               2184\n",
       "Level1_Category_Id        2184\n",
       "Level1_Category_Name      2184\n",
       "Level2_Category_Id        2184\n",
       "Level2_Category_Name      2184\n",
       "Level3_Category_Id        2184\n",
       "Level3_Category_Name      2184\n",
       "gender                       0\n",
       "unique_id                    0\n",
       "type                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_stamp                    0\n",
       "contentid                     2\n",
       "user_action                   0\n",
       "sellingprice              41368\n",
       "product_name               2177\n",
       "brand_id                   2177\n",
       "brand_name                 2177\n",
       "businessunit               2177\n",
       "product_gender           275570\n",
       "category_id                2177\n",
       "Level1_Category_Id         2177\n",
       "Level1_Category_Name       2177\n",
       "Level2_Category_Id         2177\n",
       "Level2_Category_Name       2177\n",
       "Level3_Category_Id         2177\n",
       "Level3_Category_Name       2177\n",
       "gender                  2324814\n",
       "unique_id                     0\n",
       "type                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = [\"brand_name\",\"Level1_Category_Name\",\"Level2_Category_Name\",\"Level3_Category_Name\"],inplace=True)\n",
    "df_test.drop(columns = [\"brand_name\",\"Level1_Category_Name\",\"Level2_Category_Name\",\"Level3_Category_Name\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_df = pd.DataFrame()\n",
    "groupby_df_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_df[\"user_action\"] = df.groupby(\"unique_id\",dropna=False)[\"user_action\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df_test[\"user_action\"] = df_test.groupby(\"unique_id\",dropna=False)[\"user_action\"].agg(lambda x:x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_df[\"sellingprice\"] = df.groupby(\"unique_id\",dropna=False)[\"sellingprice\"].agg(lambda x:x.mean())\n",
    "groupby_df_test[\"sellingprice\"] = df_test.groupby(\"unique_id\",dropna=False)[\"sellingprice\"].agg(lambda x:x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_df[\"contentid\"] = df.groupby(\"unique_id\",dropna=False)[\"contentid\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df_test[\"contentid\"] = df_test.groupby(\"unique_id\",dropna=False)[\"contentid\"].agg(lambda x:x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.fillna(df_test.mode().loc[0])\n",
    "df = df.fillna(df.mode().loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time_stamp', 'contentid', 'user_action', 'sellingprice',\n",
       "       'product_name', 'brand_id', 'businessunit', 'product_gender',\n",
       "       'category_id', 'Level1_Category_Id', 'Level2_Category_Id',\n",
       "       'Level3_Category_Id', 'gender', 'unique_id', 'type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_df[\"product_name\"] = df.groupby(\"unique_id\",dropna=False)[\"product_name\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df[\"brand_id\"] = df.groupby(\"unique_id\",dropna=False)[\"brand_id\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df[\"businessunit\"] = df.groupby(\"unique_id\",dropna=False)[\"businessunit\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df[\"category_id\"] = df.groupby(\"unique_id\",dropna=False)[\"category_id\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df[\"product_gender\"] = df.groupby(\"unique_id\",dropna=False)[\"product_gender\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df[\"Level1_Category_Id\"] = df.groupby(\"unique_id\",dropna=False)[\"Level1_Category_Id\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df[\"Level2_Category_Id\"] = df.groupby(\"unique_id\",dropna=False)[\"Level2_Category_Id\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df[\"Level3_Category_Id\"] = df.groupby(\"unique_id\",dropna=False)[\"Level3_Category_Id\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df[\"gender\"] = df.groupby(\"unique_id\",dropna=False)[\"gender\"].agg(lambda x:x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_df_test[\"product_name\"] = df_test.groupby(\"unique_id\",dropna=False)[\"product_name\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df_test[\"brand_id\"] = df_test.groupby(\"unique_id\",dropna=False)[\"brand_id\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df_test[\"businessunit\"] = df_test.groupby(\"unique_id\",dropna=False)[\"businessunit\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df_test[\"category_id\"] = df_test.groupby(\"unique_id\",dropna=False)[\"category_id\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df_test[\"product_gender\"] = df_test.groupby(\"unique_id\",dropna=False)[\"product_gender\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df_test[\"Level1_Category_Id\"] = df_test.groupby(\"unique_id\",dropna=False)[\"Level1_Category_Id\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df_test[\"Level2_Category_Id\"] = df_test.groupby(\"unique_id\",dropna=False)[\"Level2_Category_Id\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df_test[\"Level3_Category_Id\"] = df_test.groupby(\"unique_id\",dropna=False)[\"Level3_Category_Id\"].agg(lambda x:x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TZ timestamp to datetime64 object\n",
    "\n",
    "df['timestamp_dt'] = df.apply(lambda x: datetime.fromisoformat(x['time_stamp'].strip('Z')), axis=1)\n",
    "df_test['timestamp_dt'] = df_test.apply(lambda x: datetime.fromisoformat(x['time_stamp'].strip('Z')), axis=1)\n",
    "\n",
    "df.drop('time_stamp', axis=1, inplace=True)\n",
    "df_test.drop('time_stamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will be creating new variables month, day, day_name hour and minute. I believe that minute and day will not be \n",
    "# significant but we can decide it later.\n",
    "\n",
    "df['weekday'] = df['timestamp_dt'].apply(lambda x: x.weekday())\n",
    "df['day'] = df['timestamp_dt'].apply(lambda x: x.day)\n",
    "df['month'] = df['timestamp_dt'].apply(lambda x: x.month)\n",
    "df['hour'] = df['timestamp_dt'].apply(lambda x: x.hour)\n",
    "df['minute'] = df['timestamp_dt'].apply(lambda x: x.minute)\n",
    "\n",
    "df_test['weekday'] = df_test['timestamp_dt'].apply(lambda x: x.weekday())\n",
    "df_test['day'] = df_test['timestamp_dt'].apply(lambda x: x.day)\n",
    "df_test['month'] = df_test['timestamp_dt'].apply(lambda x: x.month)\n",
    "df_test['hour'] = df_test['timestamp_dt'].apply(lambda x: x.hour)\n",
    "df_test['minute'] = df_test['timestamp_dt'].apply(lambda x: x.minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_df_test[\"weekday\"] = df_test.groupby(\"unique_id\",dropna=False)[\"weekday\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df_test[\"day\"] = df_test.groupby(\"unique_id\",dropna=False)[\"day\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df_test[\"month\"] = df_test.groupby(\"unique_id\",dropna=False)[\"month\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df_test[\"hour\"] = df_test.groupby(\"unique_id\",dropna=False)[\"hour\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df_test[\"minute\"] = df_test.groupby(\"unique_id\",dropna=False)[\"minute\"].agg(lambda x:x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_df[\"weekday\"] = df.groupby(\"unique_id\",dropna=False)[\"weekday\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df[\"day\"] = df.groupby(\"unique_id\",dropna=False)[\"day\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df[\"month\"] = df.groupby(\"unique_id\",dropna=False)[\"month\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df[\"hour\"] = df.groupby(\"unique_id\",dropna=False)[\"hour\"].agg(lambda x:x.value_counts().index[0])\n",
    "groupby_df[\"minute\"] = df.groupby(\"unique_id\",dropna=False)[\"minute\"].agg(lambda x:x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required libraries\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = groupby_df.drop(columns = [\"gender\"])\n",
    "X_test = groupby_df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_df_merged = pd.concat([groupby_df,groupby_df_test])\n",
    "groupby_df_merged = groupby_df_merged.drop(columns = [\"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_merged = groupby_df_merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqencies = X_merged[\"contentid\"].value_counts(sort=False,normalize = False)\n",
    "idx = freqencies[freqencies < np.quantile(freqencies,0.995)].index\n",
    "X_merged[\"contentid\"] = X_merged[\"contentid\"].replace(idx, 'rare_content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqencies = X_merged[\"product_name\"].value_counts(sort=False,normalize = False)\n",
    "idx = freqencies[freqencies < np.quantile(freqencies,0.99)].index\n",
    "X_merged[\"product_name\"] = X_merged[\"product_name\"].replace(idx, 'rare_pname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqencies = X_merged[\"brand_id\"].value_counts(sort=False,normalize = False)\n",
    "idx = freqencies[freqencies < np.quantile(freqencies,0.95)].index\n",
    "X_merged[\"brand_id\"] = X_merged[\"brand_id\"].replace(idx, 'rare_bid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqencies = X_merged[\"category_id\"].value_counts(sort=False,normalize = False)\n",
    "idx = freqencies[freqencies < np.quantile(freqencies,0.90)].index\n",
    "X_merged[\"category_id\"] = X_merged[\"category_id\"].replace(idx, 'rare_categoryid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqencies = X_merged[\"Level2_Category_Id\"].value_counts(sort=False,normalize = False)\n",
    "idx = freqencies[freqencies < np.quantile(freqencies,0.50)].index\n",
    "X_merged[\"Level2_Category_Id\"] = X_merged[\"Level2_Category_Id\"].replace(idx, 'rare_category2id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqencies = X_merged[\"Level3_Category_Id\"].value_counts(sort=False,normalize = False)\n",
    "idx = freqencies[freqencies < np.quantile(freqencies,0.75)].index\n",
    "X_merged[\"Level3_Category_Id\"] = X_merged[\"Level3_Category_Id\"].replace(idx, 'rare_category3id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_merged[[\"user_action\",\"contentid\",\"product_name\",\"brand_id\",\"product_gender\",\"businessunit\",\"category_id\",\"Level1_Category_Id\",\"Level2_Category_Id\",\n",
    "  \"Level3_Category_Id\"]] = X_merged[[\"user_action\",\"contentid\",\"product_name\",\"brand_id\",\"product_gender\",\"businessunit\",\"category_id\",\"Level1_Category_Id\",\"Level2_Category_Id\",\n",
    "  \"Level3_Category_Id\"]].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_merged = pd.concat([X_merged,pd.get_dummies(X_merged[\"user_action\"],prefix = \"ua\")],axis = 1)\n",
    "X_merged = pd.concat([X_merged,pd.get_dummies(X_merged[\"product_gender\"],prefix = \"pg\")],axis = 1)\n",
    "X_merged = pd.concat([X_merged,pd.get_dummies(X_merged[\"businessunit\"],prefix = \"b\")],axis = 1)\n",
    "X_merged = pd.concat([X_merged,pd.get_dummies(X_merged[\"Level1_Category_Id\"],prefix = \"l\")],axis = 1)\n",
    "X_merged = pd.concat([X_merged,pd.get_dummies(X_merged[\"contentid\"],prefix = \"ci\")],axis = 1)\n",
    "X_merged = pd.concat([X_merged,pd.get_dummies(X_merged[\"product_name\"],prefix = \"pn\")],axis = 1)\n",
    "X_merged = pd.concat([X_merged,pd.get_dummies(X_merged[\"brand_id\"],prefix = \"bid\")],axis = 1)\n",
    "X_merged = pd.concat([X_merged,pd.get_dummies(X_merged[\"category_id\"],prefix = \"cid\")],axis = 1)\n",
    "X_merged = pd.concat([X_merged,pd.get_dummies(X_merged[\"Level2_Category_Id\"],prefix = \"c2id\")],axis = 1)\n",
    "X_merged = pd.concat([X_merged,pd.get_dummies(X_merged[\"Level3_Category_Id\"],prefix = \"c3id\")],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "618"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_merged = X_merged.drop(columns = [\"user_action\",\"product_gender\",\"businessunit\",\"category_id\",\"Level2_Category_Id\"\n",
    "                                    ,\"Level3_Category_Id\",\"Level1_Category_Id\",\"contentid\",\"product_name\",\"brand_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_merged.loc[groupby_df.index]\n",
    "X_test = X_merged.loc[groupby_df_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = groupby_df[\"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.loc[y==\"F\"] = 1\n",
    "y.loc[y==\"M\"] = 0\n",
    "y = y.astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"sellingprice\"] = X[\"sellingprice\"].fillna(X[\"sellingprice\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def pe_score(y_true, y_pred):\n",
    "    pe1 = balanced_accuracy_score(y_true, y_pred)\n",
    "    pe2 = roc_auc_score(y_true, y_pred)\n",
    "    return (pe1+pe2)/2\n",
    "\n",
    "pe_error = make_scorer(pe_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [1000], 'max_features': [256], 'max_depth': [110], 'min_samples_split': [10], 'min_samples_leaf': [2], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [1000]\n",
    "# Number of features to consider at every split\n",
    "max_features = [256]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [110]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True,False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaled_X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = pd.DataFrame(scaled_X,columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_x = PCA(n_components=25)\n",
    "principalComponents_X = pca_x.fit_transform(scaled_X)\n",
    "sum(pca_x.explained_variance_)\n",
    "pca_x.explained_variance_\n",
    "principalComponents_X = pd.DataFrame(principalComponents_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.58826152783584"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pca_x.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=4,\n",
       "             param_grid={'bootstrap': [True, False], 'max_depth': [110],\n",
       "                         'max_features': [256], 'min_samples_leaf': [2],\n",
       "                         'min_samples_split': [10], 'n_estimators': [1000]},\n",
       "             scoring=make_scorer(pe_score), verbose=100)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = GridSearchCV(estimator = rf, param_grid = random_grid,scoring = pe_error\n",
    "                               , cv = 3, verbose=100, n_jobs = 4)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pg_Kadın</th>\n",
       "      <td>0.120736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sellingprice</th>\n",
       "      <td>0.111189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pg_Erkek</th>\n",
       "      <td>0.072911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minute</th>\n",
       "      <td>0.066133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>0.058044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>0.054722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>0.032958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_1071.0</th>\n",
       "      <td>0.030532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_758.0</th>\n",
       "      <td>0.030329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bid_40.0</th>\n",
       "      <td>0.029004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_522.0</th>\n",
       "      <td>0.021900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pg_Unisex</th>\n",
       "      <td>0.021468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bid_rare_bid</th>\n",
       "      <td>0.013235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0.011720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ua_visit</th>\n",
       "      <td>0.009314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ua_search</th>\n",
       "      <td>0.008874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_1219.0</th>\n",
       "      <td>0.008334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ua_favorite</th>\n",
       "      <td>0.007928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c3id_rare_category3id</th>\n",
       "      <td>0.007579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cid_rare_categoryid</th>\n",
       "      <td>0.006955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature_importance\n",
       "pg_Kadın                         0.120736\n",
       "sellingprice                     0.111189\n",
       "pg_Erkek                         0.072911\n",
       "minute                           0.066133\n",
       "day                              0.058044\n",
       "hour                             0.054722\n",
       "weekday                          0.032958\n",
       "l_1071.0                         0.030532\n",
       "l_758.0                          0.030329\n",
       "bid_40.0                         0.029004\n",
       "l_522.0                          0.021900\n",
       "pg_Unisex                        0.021468\n",
       "bid_rare_bid                     0.013235\n",
       "month                            0.011720\n",
       "ua_visit                         0.009314\n",
       "ua_search                        0.008874\n",
       "l_1219.0                         0.008334\n",
       "ua_favorite                      0.007928\n",
       "c3id_rare_category3id            0.007579\n",
       "cid_rare_categoryid              0.006955"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_estimator_.feature_importances_\n",
    "\n",
    "rf_parameters = pd.DataFrame(rf_random.best_estimator_.feature_importances_,columns = [\"feature_importance\"],index = X.columns)\n",
    "rf_parameters.sort_values(by = \"feature_importance\",ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>(BAR + AUC)/2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.720601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>110</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.704815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bootstrap  max_depth  max_features  min_samples_leaf  min_samples_split  \\\n",
       "0       True        110           256                 2                 10   \n",
       "1      False        110           256                 2                 10   \n",
       "\n",
       "   n_estimators  (BAR + AUC)/2  \n",
       "0          1000       0.720601  \n",
       "1          1000       0.704815  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_decision_tree = pd.concat([pd.DataFrame(rf_random.cv_results_[\"params\"])\n",
    "           ,pd.DataFrame(rf_random.cv_results_[\"mean_test_score\"]\n",
    "                         , columns=[\"(BAR + AUC)/2\"])],axis=1)\n",
    "cv_results_decision_tree.sort_values(by = \"(BAR + AUC)/2\",ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [1000], 'max_features': [4, 8, 16], 'max_depth': [110], 'min_samples_split': [10], 'min_samples_leaf': [2], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [1000]\n",
    "# Number of features to consider at every split\n",
    "max_features = [4,8,16]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [110]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True,False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=4,\n",
       "             param_grid={'bootstrap': [True, False], 'max_depth': [110],\n",
       "                         'max_features': [4, 8, 16], 'min_samples_leaf': [2],\n",
       "                         'min_samples_split': [10], 'n_estimators': [1000]},\n",
       "             scoring=make_scorer(pe_score), verbose=100)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = GridSearchCV(estimator = rf, param_grid = random_grid,scoring = pe_error\n",
    "                               , cv = 3, verbose=100, n_jobs = 4)\n",
    "# Fit the random search model\n",
    "rf_random.fit(principalComponents_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>(BAR + AUC)/2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.698124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.693060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.691760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>110</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.685567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.682421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>110</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.673618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bootstrap  max_depth  max_features  min_samples_leaf  min_samples_split  \\\n",
       "2       True        110            16                 2                 10   \n",
       "1       True        110             8                 2                 10   \n",
       "0       True        110             4                 2                 10   \n",
       "4      False        110             8                 2                 10   \n",
       "3      False        110             4                 2                 10   \n",
       "5      False        110            16                 2                 10   \n",
       "\n",
       "   n_estimators  (BAR + AUC)/2  \n",
       "2          1000       0.698124  \n",
       "1          1000       0.693060  \n",
       "0          1000       0.691760  \n",
       "4          1000       0.685567  \n",
       "3          1000       0.682421  \n",
       "5          1000       0.673618  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_decision_tree = pd.concat([pd.DataFrame(rf_random.cv_results_[\"params\"])\n",
    "           ,pd.DataFrame(rf_random.cv_results_[\"mean_test_score\"]\n",
    "                         , columns=[\"(BAR + AUC)/2\"])],axis=1)\n",
    "cv_results_decision_tree.sort_values(by = \"(BAR + AUC)/2\",ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SVC(), n_jobs=4,\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf', 'sigmoid']},\n",
       "             refit=False, scoring=make_scorer(pe_score), verbose=3)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf','sigmoid']}\n",
    " \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = False,cv = 3 ,verbose = 3,scoring = pe_error,n_jobs = 4)\n",
    " \n",
    "# fitting the model for grid search\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kernel</th>\n",
       "      <th>(BAR + AUC)/2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.679659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.654121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.629212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.619302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.571676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.540615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.540137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.531551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.529910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.529910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.528458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.525606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.520739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.508431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.507685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.507515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.506477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.502836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.500488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.500488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C   gamma   kernel  (BAR + AUC)/2\n",
       "48  1000.0  0.0001      rbf       0.679659\n",
       "38   100.0  0.0001      rbf       0.654121\n",
       "36   100.0  0.0010      rbf       0.629212\n",
       "46  1000.0  0.0010      rbf       0.619302\n",
       "26    10.0  0.0010      rbf       0.571676\n",
       "16     1.0  0.0010      rbf       0.540615\n",
       "28    10.0  0.0001      rbf       0.540137\n",
       "18     1.0  0.0001      rbf       0.531551\n",
       "44  1000.0  0.0100      rbf       0.529910\n",
       "34   100.0  0.0100      rbf       0.529910\n",
       "24    10.0  0.0100      rbf       0.528458\n",
       "8      0.1  0.0001      rbf       0.525606\n",
       "14     1.0  0.0100      rbf       0.520739\n",
       "47  1000.0  0.0010  sigmoid       0.508431\n",
       "37   100.0  0.0010  sigmoid       0.507685\n",
       "27    10.0  0.0010  sigmoid       0.507515\n",
       "45  1000.0  0.0100  sigmoid       0.506477\n",
       "17     1.0  0.0010  sigmoid       0.502836\n",
       "22    10.0  0.1000      rbf       0.500488\n",
       "32   100.0  0.1000      rbf       0.500488"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_decision_tree = pd.concat([pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "           ,pd.DataFrame(grid.cv_results_[\"mean_test_score\"]\n",
    "                         , columns=[\"(BAR + AUC)/2\"])],axis=1)\n",
    "grid_results_decision_tree.sort_values(by = \"(BAR + AUC)/2\",ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SVC(), n_jobs=4,\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf', 'sigmoid']},\n",
       "             refit=False, scoring=make_scorer(pe_score), verbose=3)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf','sigmoid']}\n",
    " \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = False,cv = 3 ,verbose = 3,scoring = pe_error,n_jobs = 4)\n",
    " \n",
    "# fitting the model for grid search\n",
    "grid.fit(principalComponents_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kernel</th>\n",
       "      <th>(BAR + AUC)/2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.713908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.712123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.707790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.699035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.687015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.686271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.684232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.682469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.681416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.674920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.652057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.649666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.645846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.630401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.629927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.629545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.623539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.622453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.618830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.618681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         C   gamma   kernel  (BAR + AUC)/2\n",
       "46  1000.0  0.0010      rbf       0.713908\n",
       "24    10.0  0.0100      rbf       0.712123\n",
       "34   100.0  0.0100      rbf       0.707790\n",
       "36   100.0  0.0010      rbf       0.699035\n",
       "48  1000.0  0.0001      rbf       0.687015\n",
       "14     1.0  0.0100      rbf       0.686271\n",
       "26    10.0  0.0010      rbf       0.684232\n",
       "44  1000.0  0.0100      rbf       0.682469\n",
       "12     1.0  0.1000      rbf       0.681416\n",
       "22    10.0  0.1000      rbf       0.674920\n",
       "38   100.0  0.0001      rbf       0.652057\n",
       "37   100.0  0.0010  sigmoid       0.649666\n",
       "32   100.0  0.1000      rbf       0.645846\n",
       "49  1000.0  0.0001  sigmoid       0.630401\n",
       "39   100.0  0.0001  sigmoid       0.629927\n",
       "16     1.0  0.0010      rbf       0.629545\n",
       "4      0.1  0.0100      rbf       0.623539\n",
       "27    10.0  0.0010  sigmoid       0.622453\n",
       "47  1000.0  0.0010  sigmoid       0.618830\n",
       "25    10.0  0.0100  sigmoid       0.618681"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_decision_tree = pd.concat([pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "           ,pd.DataFrame(grid.cv_results_[\"mean_test_score\"]\n",
    "                         , columns=[\"(BAR + AUC)/2\"])],axis=1)\n",
    "grid_results_decision_tree.sort_values(by = \"(BAR + AUC)/2\",ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rf_random.predict_proba(X_test)[:,1]\n",
    "np.savetxt(\"predictions5.txt\",[prediction],delimiter=',',fmt = '%.9f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94647997, 0.99348632, 0.95822533, ..., 0.62934487, 0.66792591,\n",
       "       0.4218335 ])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
